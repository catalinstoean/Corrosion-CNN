{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model, read data and train, validate, test. Save all results, from each run to files, including the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run  0\n",
      "VGG19 application\n",
      "Found 339 images belonging to 7 classes.\n",
      "Found 113 images belonging to 7 classes.\n",
      "Found 111 images belonging to 7 classes.\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 19s 864ms/step - loss: 2.1683 - acc: 0.1512 - val_loss: 1.8267 - val_acc: 0.2655\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.26549, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun0.hdf5\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 1.8245 - acc: 0.2882 - val_loss: 1.5209 - val_acc: 0.3894\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.26549 to 0.38938, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun0.hdf5\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 1.7896 - acc: 0.3358 - val_loss: 1.5354 - val_acc: 0.3894\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.38938\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 1.5777 - acc: 0.3679 - val_loss: 1.5036 - val_acc: 0.3628\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.38938\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 1.5377 - acc: 0.3817 - val_loss: 1.2585 - val_acc: 0.4248\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.38938 to 0.42478, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun0.hdf5\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 12s 553ms/step - loss: 1.4824 - acc: 0.4102 - val_loss: 1.2724 - val_acc: 0.4690\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.42478 to 0.46903, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun0.hdf5\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 1.3262 - acc: 0.4760 - val_loss: 1.4061 - val_acc: 0.4425\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.46903\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 1.3441 - acc: 0.4386 - val_loss: 1.3274 - val_acc: 0.4513\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.46903\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 1.2752 - acc: 0.4842 - val_loss: 1.3300 - val_acc: 0.4602\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.46903\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 1.1983 - acc: 0.5732 - val_loss: 1.2007 - val_acc: 0.5133\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.46903 to 0.51327, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun0.hdf5\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 1.2223 - acc: 0.5354 - val_loss: 1.1530 - val_acc: 0.4867\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.51327\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 1.2559 - acc: 0.5329 - val_loss: 1.1765 - val_acc: 0.5752\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.51327 to 0.57522, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun0.hdf5\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 12s 553ms/step - loss: 1.1265 - acc: 0.5732 - val_loss: 1.0687 - val_acc: 0.5841\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.57522 to 0.58407, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun0.hdf5\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 12s 553ms/step - loss: 1.1846 - acc: 0.5443 - val_loss: 1.1205 - val_acc: 0.5752\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.58407\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 1.1745 - acc: 0.5557 - val_loss: 1.0486 - val_acc: 0.5929\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.58407 to 0.59292, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun0.hdf5\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 1.0992 - acc: 0.6016 - val_loss: 1.6828 - val_acc: 0.5575\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.59292\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 1.1108 - acc: 0.5471 - val_loss: 1.0299 - val_acc: 0.5752\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.59292\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 1.0541 - acc: 0.5671 - val_loss: 1.0073 - val_acc: 0.6018\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.59292 to 0.60177, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun0.hdf5\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 12s 553ms/step - loss: 1.0866 - acc: 0.5874 - val_loss: 0.9716 - val_acc: 0.6460\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.60177 to 0.64602, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun0.hdf5\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 1.1534 - acc: 0.5581 - val_loss: 0.9570 - val_acc: 0.5752\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.64602\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 1.0123 - acc: 0.6329 - val_loss: 1.0405 - val_acc: 0.6372\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.64602\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 1.0341 - acc: 0.6045 - val_loss: 1.0860 - val_acc: 0.5487\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.64602\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.9380 - acc: 0.6638 - val_loss: 0.9285 - val_acc: 0.6372\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.64602\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.9423 - acc: 0.6354 - val_loss: 1.6097 - val_acc: 0.5221\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.64602\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 12s 557ms/step - loss: 0.9977 - acc: 0.6301 - val_loss: 1.0297 - val_acc: 0.5752\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.64602\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.8776 - acc: 0.6614 - val_loss: 1.0316 - val_acc: 0.5929\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.64602\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.8961 - acc: 0.6927 - val_loss: 0.9396 - val_acc: 0.6283\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.64602\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.9881 - acc: 0.6614 - val_loss: 0.8437 - val_acc: 0.6726\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.64602 to 0.67257, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun0.hdf5\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 12s 553ms/step - loss: 0.8729 - acc: 0.6520 - val_loss: 0.8679 - val_acc: 0.6637\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.67257\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.8462 - acc: 0.6923 - val_loss: 0.9449 - val_acc: 0.6283\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.67257\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.8055 - acc: 0.6898 - val_loss: 0.8668 - val_acc: 0.6372\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.67257\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.8118 - acc: 0.6898 - val_loss: 0.8059 - val_acc: 0.6814\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.67257 to 0.68142, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun0.hdf5\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.7454 - acc: 0.7240 - val_loss: 0.9768 - val_acc: 0.6726\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.68142\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.7831 - acc: 0.6984 - val_loss: 0.9837 - val_acc: 0.6018\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.68142\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.9482 - acc: 0.6606 - val_loss: 0.8504 - val_acc: 0.6814\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.68142\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.7426 - acc: 0.7325 - val_loss: 1.0945 - val_acc: 0.6195\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.68142\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.6986 - acc: 0.7382 - val_loss: 0.9506 - val_acc: 0.5929\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.68142\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.7787 - acc: 0.6894 - val_loss: 0.7917 - val_acc: 0.7168\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.68142 to 0.71681, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun0.hdf5\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.7208 - acc: 0.7467 - val_loss: 1.0426 - val_acc: 0.6637\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.71681\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.8057 - acc: 0.6667 - val_loss: 1.1413 - val_acc: 0.6726\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.71681\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.7257 - acc: 0.7118 - val_loss: 0.8319 - val_acc: 0.7168\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.71681\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.7233 - acc: 0.7094 - val_loss: 0.8297 - val_acc: 0.6637\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.71681\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.7843 - acc: 0.7268 - val_loss: 0.8702 - val_acc: 0.6283\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.71681\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.8106 - acc: 0.7150 - val_loss: 0.8899 - val_acc: 0.6460\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.71681\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.6095 - acc: 0.7809 - val_loss: 0.9599 - val_acc: 0.6637\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.71681\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.8152 - acc: 0.7118 - val_loss: 0.9646 - val_acc: 0.6283\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.71681\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.4988 - acc: 0.7980 - val_loss: 1.0400 - val_acc: 0.6372\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.71681\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.7167 - acc: 0.7378 - val_loss: 0.8798 - val_acc: 0.6726\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.71681\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.5947 - acc: 0.7862 - val_loss: 1.2276 - val_acc: 0.6283\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.71681\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.7436 - acc: 0.6862 - val_loss: 0.9046 - val_acc: 0.6726\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.71681\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.6147 - acc: 0.7805 - val_loss: 0.9134 - val_acc: 0.6814\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.71681\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.6398 - acc: 0.7866 - val_loss: 1.1130 - val_acc: 0.6106\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.71681\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.5262 - acc: 0.8037 - val_loss: 0.9895 - val_acc: 0.6726\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.71681\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.5710 - acc: 0.7691 - val_loss: 0.8710 - val_acc: 0.6726\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.71681\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.5021 - acc: 0.8293 - val_loss: 1.4839 - val_acc: 0.6018\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.71681\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.5714 - acc: 0.7919 - val_loss: 1.1891 - val_acc: 0.6106\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.71681\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.5153 - acc: 0.8061 - val_loss: 1.5501 - val_acc: 0.5752\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.71681\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.5919 - acc: 0.7919 - val_loss: 1.2346 - val_acc: 0.5664\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.71681\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.5035 - acc: 0.8406 - val_loss: 0.9002 - val_acc: 0.7168\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.71681\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.5608 - acc: 0.7976 - val_loss: 0.9704 - val_acc: 0.6814\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.71681\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.5705 - acc: 0.8037 - val_loss: 1.1276 - val_acc: 0.6549\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.71681\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.5058 - acc: 0.8317 - val_loss: 0.9761 - val_acc: 0.6726\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.71681\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.5924 - acc: 0.7947 - val_loss: 1.0456 - val_acc: 0.6195\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.71681\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.4664 - acc: 0.8207 - val_loss: 0.9404 - val_acc: 0.6726\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.71681\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.4934 - acc: 0.8236 - val_loss: 0.9638 - val_acc: 0.7080\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.71681\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.4394 - acc: 0.8179 - val_loss: 1.0479 - val_acc: 0.6460\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.71681\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.5319 - acc: 0.8171 - val_loss: 1.1555 - val_acc: 0.6460\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.71681\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.5499 - acc: 0.8179 - val_loss: 1.0580 - val_acc: 0.7080\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.71681\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.4526 - acc: 0.8350 - val_loss: 0.9395 - val_acc: 0.6814\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.71681\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.4971 - acc: 0.8321 - val_loss: 1.0908 - val_acc: 0.6372\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.71681\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.4713 - acc: 0.8260 - val_loss: 0.9823 - val_acc: 0.6991\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.71681\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.4352 - acc: 0.8350 - val_loss: 0.9415 - val_acc: 0.6814\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.71681\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.5402 - acc: 0.8118 - val_loss: 1.0413 - val_acc: 0.6903\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.71681\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.3637 - acc: 0.8549 - val_loss: 1.4118 - val_acc: 0.6726\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.71681\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.4387 - acc: 0.8606 - val_loss: 1.0612 - val_acc: 0.6549\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.71681\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.3925 - acc: 0.8512 - val_loss: 1.3369 - val_acc: 0.6814\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.71681\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.3668 - acc: 0.8833 - val_loss: 1.1006 - val_acc: 0.6195\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.71681\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.3787 - acc: 0.8549 - val_loss: 2.0909 - val_acc: 0.5575\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.71681\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.4179 - acc: 0.8549 - val_loss: 1.3409 - val_acc: 0.6460\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.71681\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.3699 - acc: 0.8919 - val_loss: 1.1520 - val_acc: 0.6903\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.71681\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.3380 - acc: 0.8719 - val_loss: 1.4319 - val_acc: 0.6283\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.71681\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.3034 - acc: 0.9061 - val_loss: 2.3954 - val_acc: 0.6018\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.71681\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 12s 554ms/step - loss: 0.3679 - acc: 0.8634 - val_loss: 1.2018 - val_acc: 0.6726\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.71681\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.3912 - acc: 0.8776 - val_loss: 1.5337 - val_acc: 0.6283\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.71681\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.3031 - acc: 0.8890 - val_loss: 1.2405 - val_acc: 0.7168\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.71681\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.4154 - acc: 0.8719 - val_loss: 1.3751 - val_acc: 0.6991\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.71681\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.2503 - acc: 0.9118 - val_loss: 1.4437 - val_acc: 0.6814\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.71681\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 12s 559ms/step - loss: 0.3957 - acc: 0.8516 - val_loss: 1.9467 - val_acc: 0.6283\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.71681\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.4930 - acc: 0.8459 - val_loss: 1.5267 - val_acc: 0.7080\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.71681\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.2380 - acc: 0.9089 - val_loss: 1.6398 - val_acc: 0.6814\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.71681\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.3387 - acc: 0.9004 - val_loss: 1.4369 - val_acc: 0.6726\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.71681\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.3061 - acc: 0.9118 - val_loss: 1.5947 - val_acc: 0.6195\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.71681\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 12s 557ms/step - loss: 0.5117 - acc: 0.8606 - val_loss: 1.4561 - val_acc: 0.6283\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.71681\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.2800 - acc: 0.9146 - val_loss: 1.8294 - val_acc: 0.6195\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.71681\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.4495 - acc: 0.8516 - val_loss: 1.5827 - val_acc: 0.6549\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.71681\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 0.3563 - acc: 0.8862 - val_loss: 1.4185 - val_acc: 0.6991\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.71681\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.3208 - acc: 0.8976 - val_loss: 2.1928 - val_acc: 0.6195\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.71681\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.4650 - acc: 0.8374 - val_loss: 2.2900 - val_acc: 0.5841\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.71681\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 0.3993 - acc: 0.8833 - val_loss: 1.2855 - val_acc: 0.6726\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.71681\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 12s 559ms/step - loss: 0.3204 - acc: 0.8858 - val_loss: 1.5236 - val_acc: 0.6726\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.71681\n",
      "111/111 [==============================] - 6s 54ms/step\n",
      "Loss and evaluation on the test set in run  0 : [0.9832938050364589, 0.5675675702524615]\n",
      "The following file is saved:  TVT\\SavedResults\\All\\VGG19\\ResultsRuntimeCNN0.txt\n",
      "Starting run  1\n",
      "VGG19 application\n",
      "Found 339 images belonging to 7 classes.\n",
      "Found 113 images belonging to 7 classes.\n",
      "Found 111 images belonging to 7 classes.\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 14s 624ms/step - loss: 2.2865 - acc: 0.1939 - val_loss: 1.7573 - val_acc: 0.2832\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.28319, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun1.hdf5\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 1.7442 - acc: 0.3077 - val_loss: 1.3610 - val_acc: 0.4779\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.28319 to 0.47788, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun1.hdf5\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 1.6138 - acc: 0.3842 - val_loss: 1.2080 - val_acc: 0.5752\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.47788 to 0.57522, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun1.hdf5\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 12s 557ms/step - loss: 1.4241 - acc: 0.4390 - val_loss: 1.7750 - val_acc: 0.3982\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.57522\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 1.3965 - acc: 0.4557 - val_loss: 1.2446 - val_acc: 0.5044\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.57522\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 1.3823 - acc: 0.4756 - val_loss: 1.1712 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.57522\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 12s 558ms/step - loss: 1.3805 - acc: 0.4476 - val_loss: 1.1641 - val_acc: 0.5310\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.57522\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 12s 557ms/step - loss: 1.2961 - acc: 0.4813 - val_loss: 1.1850 - val_acc: 0.5487\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.57522\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 12s 557ms/step - loss: 1.2662 - acc: 0.5443 - val_loss: 1.0712 - val_acc: 0.6018\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.57522 to 0.60177, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun1.hdf5\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 12s 559ms/step - loss: 1.1821 - acc: 0.5589 - val_loss: 1.0164 - val_acc: 0.5664\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.60177\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 1.1511 - acc: 0.5362 - val_loss: 1.0546 - val_acc: 0.6018\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.60177\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 12s 558ms/step - loss: 1.1363 - acc: 0.5585 - val_loss: 1.0115 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.60177\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 1.1556 - acc: 0.5301 - val_loss: 1.1334 - val_acc: 0.5487\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.60177\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 12s 557ms/step - loss: 1.0070 - acc: 0.6012 - val_loss: 0.9867 - val_acc: 0.6106\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.60177 to 0.61062, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun1.hdf5\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 12s 558ms/step - loss: 1.1526 - acc: 0.5695 - val_loss: 1.0870 - val_acc: 0.5221\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.61062\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 12s 557ms/step - loss: 1.0743 - acc: 0.5817 - val_loss: 1.0552 - val_acc: 0.5752\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.61062\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 12s 557ms/step - loss: 0.9523 - acc: 0.6098 - val_loss: 0.9169 - val_acc: 0.6460\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.61062 to 0.64602, saving model to TVT\\SavedResults\\All\\VGG19\\WeightsBestRun1.hdf5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5120c75696a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mapps\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'VGG19'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ResNet50'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Xception'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'InceptionV3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[0mrunCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplication\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoOfRuns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m197\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[0mfrequency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2500\u001b[0m  \u001b[1;31m# Set Frequency To 2500 Hertz\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[0mduration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m  \u001b[1;31m# Set Duration To 1000 ms == 1 second\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-5120c75696a7>\u001b[0m in \u001b[0;36mrunCNN\u001b[1;34m(application, noOfRuns, epochs, batch_size, image_size)\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m                 validation_steps=jpgCounterValid // batch_size)\n\u001b[0m\u001b[0;32m    125\u001b[0m         \u001b[0melapsedTrainingTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1415\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    245\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m             \u001b[0mepoch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    442\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m   1083\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m         \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mmodel_weights_group\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mmodel_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_weights_group\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minclude_optimizer\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36msave_weights_to_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[0msymbolic_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m         \u001b[0mweight_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m         \u001b[0mweight_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[1;34m(ops)\u001b[0m\n\u001b[0;32m   2388\u001b[0m     \"\"\"\n\u001b[0;32m   2389\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2390\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2391\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2392\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import os\n",
    "import glob #to count jpg files\n",
    "import h5py\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras import regularizers, optimizers\n",
    "\n",
    "from keras.applications import VGG19, ResNet50, xception, inception_v3\n",
    "\n",
    "import time\n",
    "import winsound #to play a sound when the program finishes\n",
    "\n",
    "image_size = 197\n",
    "\n",
    "def runCNN(application = 'ResNet50', noOfRuns = 1, epochs = 100, batch_size = 32, image_size = 197):\n",
    "    \n",
    "    trainPath = 'TVT/TVTAll/train'\n",
    "    validPath = 'TVT/TVTAll/validation'\n",
    "    testPath = 'TVT/TVTAll/test'\n",
    "\n",
    "    jpgCounterValid = len(glob.glob(validPath + \"/**/*.jpg\"))\n",
    "    jpgCounterTest = len(glob.glob(testPath + \"/**/*.jpg\"))\n",
    "    \n",
    "    for i in range (0, noOfRuns):\n",
    "        print(\"Starting run \", i)\n",
    "        start_time = time.time()\n",
    "        keras.backend.clear_session()\n",
    "        if application == 'ResNet50':\n",
    "            res_conv = ResNet50(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "            print('ResNet50 application')\n",
    "        elif application == 'VGG19':\n",
    "            res_conv = VGG19(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "            print('VGG19 application')\n",
    "        elif application == 'Xception':\n",
    "            res_conv = xception.Xception(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "            print('Xception application')\n",
    "        elif application == 'InceptionV3':\n",
    "            res_conv = inception_v3.InceptionV3(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "            print('InceptionV3 application')\n",
    "        \n",
    "        # Create the model\n",
    "        # Freeze the layers except the last 4 layers\n",
    "        for layer in res_conv.layers[:-4]:\n",
    "            layer.trainable = False\n",
    "        model1 = Sequential()\n",
    "\n",
    "        # Add the res convolutional base model\n",
    "        model1.add(res_conv)\n",
    "\n",
    "        # Add new layers\n",
    "        model1.add(Flatten())\n",
    "        model1.add(Dense(1024, activation='relu'))\n",
    "        model1.add(Dropout(0.5))\n",
    "\n",
    "        model1.add(Dense(7, activation='softmax'))\n",
    "       \n",
    "\n",
    "        lossValue = 'categorical_crossentropy'\n",
    "        classModeValue = 'categorical'\n",
    "        \n",
    "        model1.compile(loss=lossValue, optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])\n",
    "        # this is the augmentation configuration we will use for training\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                              rotation_range=20,\n",
    "                              width_shift_range=0.2,\n",
    "                              height_shift_range=0.2,\n",
    "                              horizontal_flip=True,\n",
    "                              fill_mode='nearest')\n",
    "\n",
    "        # this is the augmentation configuration we will use for testing:\n",
    "        # only rescaling\n",
    "        valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        seed = 5\n",
    "\n",
    "        # this is a generator that will read pictures found in\n",
    "        # subfolDers of 'data/train', and indefinitely generate\n",
    "        # batches of augmented image data\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "                trainPath,  # this is the target directory\n",
    "                target_size=(image_size, image_size),\n",
    "                batch_size=batch_size,\n",
    "                class_mode=classModeValue, seed=seed, shuffle = True)  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "        # this is a similar generator, for validation data\n",
    "        validation_generator = valid_datagen.flow_from_directory(\n",
    "                validPath,\n",
    "                target_size=(image_size, image_size),\n",
    "                batch_size=batch_size,\n",
    "                class_mode=classModeValue, shuffle = False)\n",
    "\n",
    "        test_generator = test_datagen.flow_from_directory(\n",
    "                testPath,\n",
    "                target_size=(image_size, image_size),\n",
    "                batch_size=jpgCounterTest,\n",
    "                class_mode=classModeValue, shuffle = False)\n",
    "        \n",
    "        outputFolder = 'TVT\\SavedResults\\\\All\\\\' + application\n",
    "        #create the folder\n",
    "        if not os.path.exists(outputFolder):\n",
    "            os.makedirs(outputFolder)\n",
    "            \n",
    "        filepath = outputFolder + \"\\WeightsBestRun\" + str(i) +\".hdf5\"\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "        callbacks_list = [checkpoint]\n",
    "\n",
    "        history2 = model1.fit_generator(\n",
    "                train_generator,\n",
    "                #steps_per_epoch=100,#2000 // batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data=validation_generator,\n",
    "                callbacks=callbacks_list,\n",
    "                validation_steps=jpgCounterValid // batch_size)\n",
    "        elapsedTrainingTime = time.time() - start_time\n",
    "        model1.load_weights(filepath)\n",
    "\n",
    "        xTest, yTest = test_generator.next()\n",
    "        evaluation = model1.evaluate(xTest, yTest)\n",
    "        print(\"Loss and evaluation on the test set in run \", i, \":\", evaluation)\n",
    "\n",
    "        #######################################\n",
    "\n",
    "        #save results to file\n",
    "        #import os.path\n",
    "        outputFileName = outputFolder + '\\ResultsCNN.txt'        \n",
    "        if os.path.isfile(outputFileName):#if the file exists, add to it, otherwise create it\n",
    "            f = open(outputFileName,'a')\n",
    "\n",
    "            f.write(str(i) + '\\t' + str(epochs) + '\\t' + str(batch_size) + '\\t' + str(image_size) \n",
    "                    + '\\t' + str(noOfRuns) + '\\t' + str(jpgCounterValid) + '\\t' + str(jpgCounterTest) \n",
    "                    + '\\t' + str(evaluation[0]) + '\\t' + str(evaluation[1])\n",
    "                    + '\\t' + str(min(history2.history['loss'])) + '\\t' + str(max(history2.history['acc'])) \n",
    "                    + '\\t' + str(min(history2.history['val_loss'])) + '\\t' + str(max(history2.history['val_acc'])) \n",
    "                    + '\\t' + str(elapsedTrainingTime) + '\\n')\n",
    "            f.close() #I did not test if these close() are necessary. It works without them\n",
    "        else:\n",
    "            f = open(outputFileName,'w')\n",
    "            f.write('currentRun\\tepochs\\tbatch_size\\timage_size\\tnoOfRuns\\tvalidationImages\\ttestImages\\ttestLoss\\ttestAccuracy\\tminTrainLoss\\tmaxTrainAcc\\tminValidLoss\\tmaxValidAcc\\telapsedTrainingTime\\n')\n",
    "            f.close()\n",
    "            f = open(outputFileName,'a')\n",
    "            f.write(str(i) + '\\t' + str(epochs) + '\\t' + str(batch_size) + '\\t' + str(image_size) \n",
    "                    + '\\t' + str(noOfRuns) + '\\t' + str(jpgCounterValid) + '\\t' + str(jpgCounterTest) \n",
    "                    + '\\t' + str(evaluation[0]) + '\\t' + str(evaluation[1])\n",
    "                    + '\\t' + str(min(history2.history['loss'])) + '\\t' + str(max(history2.history['acc'])) \n",
    "                    + '\\t' + str(min(history2.history['val_loss'])) + '\\t' + str(max(history2.history['val_acc'])) \n",
    "                    + '\\t' + str(elapsedTrainingTime) + '\\n')\n",
    "            f.close()\n",
    "        #save acc and loos for train and validation during evolution\n",
    "        outputFileRuntime = outputFolder + '\\ResultsRuntimeCNN' + str(i) + '.txt'\n",
    "        print('The following file is saved: ', outputFileRuntime)\n",
    "        np.savetxt(outputFileRuntime, np.c_[history2.history['loss'], history2.history['val_loss'], history2.history['acc'], history2.history['val_acc']])\n",
    "\n",
    "    print(noOfRuns, ' runs are over and the result files are saved.')\n",
    "\n",
    "# 'OlAPVCVLP', 'OlEtalonCV' = over \n",
    "# 'OlEtalonLP' gata cu 'VGG19', 'ResNet50'\n",
    "\n",
    "for apps in ['VGG19', 'ResNet50', 'Xception', 'InceptionV3']:\n",
    "    runCNN(application = apps, noOfRuns = 10, epochs = 100, batch_size = 16, image_size = 197)\n",
    "frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second\n",
    "#notify that the run is over\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a model and compute confusion matrices from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV3 application  0\n",
      "Found 111 images belonging to 7 classes.\n",
      "It took  6.0706117153167725  seconds to classify  111  files, that is  0.054690195633484436  seconds per file.\n",
      "InceptionV3 application  1\n",
      "Found 111 images belonging to 7 classes.\n",
      "It took  3.928145408630371  seconds to classify  111  files, that is  0.035388697375048385  seconds per file.\n",
      "InceptionV3 application  2\n",
      "Found 111 images belonging to 7 classes.\n",
      "It took  3.945848226547241  seconds to classify  111  files, that is  0.035548182221146314  seconds per file.\n",
      "InceptionV3 application  3\n",
      "Found 111 images belonging to 7 classes.\n",
      "It took  4.02634072303772  seconds to classify  111  files, that is  0.03627333984718666  seconds per file.\n",
      "InceptionV3 application  4\n",
      "Found 111 images belonging to 7 classes.\n",
      "It took  3.9039859771728516  seconds to classify  111  files, that is  0.03517104483939506  seconds per file.\n",
      "InceptionV3 application  5\n",
      "Found 111 images belonging to 7 classes.\n",
      "It took  3.90279483795166  seconds to classify  111  files, that is  0.035160313855420365  seconds per file.\n",
      "InceptionV3 application  6\n",
      "Found 111 images belonging to 7 classes.\n",
      "It took  3.864328622817993  seconds to classify  111  files, that is  0.034813771376738675  seconds per file.\n",
      "InceptionV3 application  7\n",
      "Found 111 images belonging to 7 classes.\n",
      "It took  3.9351577758789062  seconds to classify  111  files, that is  0.03545187185476492  seconds per file.\n",
      "InceptionV3 application  8\n",
      "Found 111 images belonging to 7 classes.\n",
      "It took  3.8992459774017334  seconds to classify  111  files, that is  0.035128342138754355  seconds per file.\n",
      "InceptionV3 application  9\n",
      "Found 111 images belonging to 7 classes.\n",
      "It took  4.022607803344727  seconds to classify  111  files, that is  0.03623970994004258  seconds per file.\n",
      "[[ 7.3  2.4  3.3  1.5  0.5  0.6  0.4]\n",
      " [ 2.7  6.4  1.5  2.   0.   0.9  3.5]\n",
      " [ 1.8  4.8  3.7  1.   0.3  0.8  0.6]\n",
      " [ 0.4  0.9  0.6 11.   0.   0.5  3.6]\n",
      " [ 0.1  0.2  0.5  0.1 11.   2.7  2.4]\n",
      " [ 0.8  0.5  1.2  1.4  5.4  5.2  0.5]\n",
      " [ 0.5  0.4  0.   7.   0.4  0.   7.7]]\n",
      "Confusion matrix, without normalization\n",
      "[[ 7.3  2.4  3.3  1.5  0.5  0.6  0.4]\n",
      " [ 2.7  6.4  1.5  2.   0.   0.9  3.5]\n",
      " [ 1.8  4.8  3.7  1.   0.3  0.8  0.6]\n",
      " [ 0.4  0.9  0.6 11.   0.   0.5  3.6]\n",
      " [ 0.1  0.2  0.5  0.1 11.   2.7  2.4]\n",
      " [ 0.8  0.5  1.2  1.4  5.4  5.2  0.5]\n",
      " [ 0.5  0.4  0.   7.   0.4  0.   7.7]]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.applications import VGG19, ResNet50, xception, inception_v3\n",
    "import os\n",
    "\n",
    "import time #to measure runtime\n",
    "import keras\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import glob #to count jpg files\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues, \n",
    "                          fileName = 'CM.pdf'):\n",
    "\n",
    "    f = plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]        \n",
    "        cm = np.around(100*cm, decimals = 1)\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    #the matrix could be saved as pdf from the method\n",
    "    f.savefig(fileName, bbox_inches='tight')\n",
    "\n",
    "image_size = 197 # should be the same as in the call of runCNN\n",
    "\n",
    "#just change application to the desired architecture\n",
    "application = 'InceptionV3'#'ResNet50'\n",
    "#application = 'ResNet50'\n",
    "runNo = 0\n",
    "\n",
    "#10 is the total no of runs\n",
    "#in cmTest all cm will be gathered to compute the average afterwards\n",
    "cmTest = np.ndarray(shape=(10, 7, 7), dtype=float)\n",
    "\n",
    "#compute an average over 10 runs for the confusion matrices\n",
    "for runNo in range(0, 10):\n",
    "    keras.backend.clear_session()\n",
    "    modelFilePath = 'TVT\\SavedResults\\\\All\\\\' + application + \"\\WeightsBestRun\" + str(runNo) +\".hdf5\"\n",
    "    \n",
    "    \n",
    "    lossValue = 'categorical_crossentropy'\n",
    "    classModeValue = 'categorical'\n",
    "    \n",
    "    if application == 'ResNet50':\n",
    "        res_conv = ResNet50(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "        print('ResNet50 application ', runNo)\n",
    "    elif application == 'VGG19':\n",
    "        res_conv = VGG19(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "        print('VGG19 application ', runNo)\n",
    "    elif application == 'Xception':\n",
    "        res_conv = xception.Xception(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "        print('Xception application ', runNo)\n",
    "    elif application == 'InceptionV3':\n",
    "        res_conv = inception_v3.InceptionV3(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "        print('InceptionV3 application ', runNo)\n",
    "\n",
    "\n",
    "    # Freeze the layers except the last 4 layers\n",
    "    for layer in res_conv.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Create the model\n",
    "    model1 = Sequential()\n",
    "\n",
    "    # Add the res convolutional base model\n",
    "    model1.add(res_conv)\n",
    "\n",
    "    # Add new layers\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(1024, activation='relu'))\n",
    "    model1.add(Dropout(0.5))\n",
    "\n",
    "    \n",
    "    model1.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    model1.load_weights(modelFilePath)\n",
    "\n",
    "    testPath = 'TVT/TVTAll/test'\n",
    "    jpgCounterTest = len(glob.glob(testPath + \"/**/*.jpg\"))\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "                    testPath,\n",
    "                    target_size=(image_size, image_size),\n",
    "                    batch_size=jpgCounterTest,\n",
    "                    class_mode=classModeValue, shuffle = False)\n",
    "\n",
    "    testBatch, trueLabelsTest = next(test_generator)\n",
    "    \n",
    "    startTime = time.time()\n",
    "    predLabelsTest = model1.predict(testBatch)\n",
    "    stopTime = time.time()\n",
    "    \n",
    "    print('It took ', (stopTime - startTime), ' seconds to classify ', jpgCounterTest, ' files, that is ', ((stopTime - startTime)/jpgCounterTest), ' seconds per file.')\n",
    "\n",
    "    \n",
    "    cmTest[runNo] = confusion_matrix(trueLabelsTest.argmax(1), predLabelsTest.argmax(axis=-1))\n",
    "\n",
    "averageCM = np.mean( np.array(cmTest), axis=0 )\n",
    "\n",
    "print(averageCM)\n",
    "\n",
    "cm_plot_labels = ['$CV_{Noinhib}$', '$CV_{PVA}$', '$CV_{PVA/nAg}$', '$LP_{Noinhib}$', '$LP_{PVA}$', '$LP_{PVA/nAg}$', 'Standard']\n",
    "\n",
    "\n",
    "outputFolder = 'TVT\\SavedResults\\\\All\\\\' + application\n",
    "#create the folder\n",
    "if not os.path.exists(outputFolder):\n",
    "    os.makedirs(outputFolder)\n",
    "\n",
    "cmFileName = outputFolder + \"\\cmAll\" + application + \".pdf\"\n",
    "\n",
    "plot_confusion_matrix(averageCM, cm_plot_labels, normalize = False, title='', fileName = cmFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
